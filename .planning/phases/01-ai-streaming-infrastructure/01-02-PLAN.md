---
phase: 01-ai-streaming-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - sidekiq-webapp/src/app/(dashboard)/chat/page.tsx
  - sidekiq-webapp/src/app/(dashboard)/chat/layout.tsx
  - sidekiq-webapp/src/components/chat/chat-interface.tsx
  - sidekiq-webapp/src/components/chat/message-list.tsx
  - sidekiq-webapp/src/components/chat/message-item.tsx
  - sidekiq-webapp/src/components/chat/chat-input.tsx
  - sidekiq-webapp/src/components/chat/typing-indicator.tsx
  - sidekiq-webapp/src/components/chat/chat-scroll-anchor.tsx
  - sidekiq-webapp/src/hooks/use-auto-scroll.ts
autonomous: true

must_haves:
  truths:
    - "User can type a message and send it"
    - "User sees their message appear immediately (optimistic)"
    - "User sees streaming AI response token-by-token"
    - "User sees typing indicator while AI is thinking"
    - "Chat auto-scrolls during streaming unless user scrolls up"
    - "User can stop streaming with a stop button"
  artifacts:
    - path: "sidekiq-webapp/src/app/(dashboard)/chat/page.tsx"
      provides: "Chat page entry point"
      min_lines: 15
    - path: "sidekiq-webapp/src/components/chat/chat-interface.tsx"
      provides: "Main chat container with useChat hook"
      exports: ["ChatInterface"]
    - path: "sidekiq-webapp/src/components/chat/message-list.tsx"
      provides: "Message rendering with streaming support"
      exports: ["MessageList"]
    - path: "sidekiq-webapp/src/components/chat/chat-input.tsx"
      provides: "Input form with send/stop buttons"
      exports: ["ChatInput"]
    - path: "sidekiq-webapp/src/components/chat/typing-indicator.tsx"
      provides: "Three-dot pulsing indicator"
      exports: ["TypingIndicator"]
  key_links:
    - from: "sidekiq-webapp/src/components/chat/chat-interface.tsx"
      to: "/api/chat"
      via: "useChat hook api option"
      pattern: "useChat.*api.*['\"/]api/chat"
    - from: "sidekiq-webapp/src/components/chat/chat-interface.tsx"
      to: "sidekiq-webapp/src/components/chat/message-list.tsx"
      via: "renders MessageList with messages prop"
      pattern: "<MessageList"
---

<objective>
Build the chat UI components that consume the streaming API using Vercel AI SDK's useChat hook.

Purpose: Provide the user-facing interface for sending messages and viewing streaming AI responses. This completes the end-to-end chat flow.

Output:
- Chat page at `/chat` route
- ChatInterface component with useChat hook integration
- MessageList and MessageItem components for rendering
- ChatInput with send/stop functionality
- TypingIndicator for streaming feedback
- Smart auto-scroll behavior
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-ai-streaming-infrastructure/01-RESEARCH.md
@.planning/phases/01-ai-streaming-infrastructure/01-CONTEXT.md
@.planning/phases/01-ai-streaming-infrastructure/01-01-SUMMARY.md
@sidekiq-webapp/src/components/ui/button.tsx
@sidekiq-webapp/src/components/ui/textarea.tsx
@sidekiq-webapp/src/components/ui/avatar.tsx
@sidekiq-webapp/src/app/(dashboard)/layout.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create chat page and layout structure</name>
  <files>
    sidekiq-webapp/src/app/(dashboard)/chat/page.tsx
    sidekiq-webapp/src/app/(dashboard)/chat/layout.tsx
  </files>
  <action>
Create `src/app/(dashboard)/chat/layout.tsx`:
- Simple layout wrapper (children only for now, sidebar comes in Phase 5)
- Add flex layout taking full height

Create `src/app/(dashboard)/chat/page.tsx`:
- Server component that renders ChatInterface
- For MVP: Create or get a default thread for the user
- Import ChatInterface (client component) and render with threadId prop
- Use a hardcoded thread approach for now:
  ```typescript
  // Temporary: Create thread on first visit if none exists
  // Thread management comes in Phase 3
  const session = await getSession();
  if (!session) redirect('/sign-in');

  // Find or create default thread
  let thread = await db.query.threads.findFirst({
    where: eq(threads.userId, session.user.id),
    orderBy: desc(threads.lastActivityAt),
  });

  if (!thread) {
    const threadId = nanoid();
    await db.insert(threads).values({
      id: threadId,
      userId: session.user.id,
      title: 'New Chat',
      lastActivityAt: new Date(),
    });
    thread = { id: threadId };
  }
  ```
- Render `<ChatInterface threadId={thread.id} />`

This is intentionally minimal. Thread creation UI comes in Phase 3.
  </action>
  <verify>
Navigate to `/chat` in browser (while authenticated).
Page loads without errors.
ChatInterface component renders.
  </verify>
  <done>Chat route accessible at /chat, renders ChatInterface with thread context</done>
</task>

<task type="auto">
  <name>Task 2: Create chat components with useChat integration</name>
  <files>
    sidekiq-webapp/src/components/chat/chat-interface.tsx
    sidekiq-webapp/src/components/chat/message-list.tsx
    sidekiq-webapp/src/components/chat/message-item.tsx
    sidekiq-webapp/src/components/chat/chat-input.tsx
    sidekiq-webapp/src/components/chat/typing-indicator.tsx
    sidekiq-webapp/src/components/chat/chat-scroll-anchor.tsx
    sidekiq-webapp/src/hooks/use-auto-scroll.ts
  </files>
  <action>
Create `src/components/chat/chat-interface.tsx` (client component):
```typescript
'use client';

import { useChat } from '@ai-sdk/react';
import { MessageList } from './message-list';
import { ChatInput } from './chat-input';
import { TypingIndicator } from './typing-indicator';
import { ChatScrollAnchor } from './chat-scroll-anchor';
import { useRef } from 'react';

interface ChatInterfaceProps {
  threadId: string;
  initialMessages?: UIMessage[]; // For loading from DB (Phase 3)
}

export function ChatInterface({ threadId, initialMessages = [] }: ChatInterfaceProps) {
  const scrollContainerRef = useRef<HTMLDivElement>(null);

  const {
    messages,
    input,
    setInput,
    handleSubmit,
    status,
    stop,
    error,
  } = useChat({
    api: '/api/chat',
    body: { threadId },
    initialMessages,
    onError: (error) => {
      console.error('Chat error:', error);
      // Toast notification (use sonner) - will be enhanced in Phase 10
    },
  });

  const isStreaming = status === 'streaming' || status === 'submitted';

  return (
    <div className="flex h-full flex-col">
      <div
        ref={scrollContainerRef}
        className="flex-1 overflow-y-auto px-4"
      >
        <div className="mx-auto max-w-3xl py-4">
          <MessageList messages={messages} />
          {isStreaming && messages[messages.length - 1]?.role === 'user' && (
            <TypingIndicator />
          )}
          <ChatScrollAnchor
            isStreaming={isStreaming}
            messagesLength={messages.length}
            scrollContainer={scrollContainerRef}
          />
        </div>
      </div>

      <div className="border-t border-zinc-800 bg-zinc-950 px-4 py-4">
        <div className="mx-auto max-w-3xl">
          <ChatInput
            input={input}
            setInput={setInput}
            onSubmit={handleSubmit}
            isStreaming={isStreaming}
            onStop={stop}
          />
        </div>
      </div>
    </div>
  );
}
```

Create `src/components/chat/message-list.tsx`:
- Map over messages array
- Render MessageItem for each
- Handle empty state (no messages yet)

Create `src/components/chat/message-item.tsx`:
- Props: message (UIMessage type from ai)
- Render user messages right-aligned with user styling
- Render assistant messages left-aligned with AI styling
- Extract text content from message.parts
- Use Avatar component for visual distinction
- Styling: glassmorphism hints (translucent backgrounds, subtle borders)

Create `src/components/chat/chat-input.tsx`:
- Textarea (auto-resize) with form wrapper
- Send button (disabled when empty or streaming)
- Stop button (shown only when streaming)
- Handle Enter to send (Shift+Enter for newline)
- Props: input, setInput, onSubmit, isStreaming, onStop

Create `src/components/chat/typing-indicator.tsx`:
- Three dots with staggered pulse animation
- "AI is thinking..." text
- Use Tailwind animate-pulse with animation-delay

Create `src/components/chat/chat-scroll-anchor.tsx`:
- Use Intersection Observer pattern from research
- Auto-scroll when streaming AND user is near bottom
- Don't auto-scroll if user has scrolled up
- Invisible 1px anchor at bottom

Create `src/hooks/use-auto-scroll.ts`:
- Custom hook for scroll logic
- Track if user is near bottom
- Provide scrollToBottom function
  </action>
  <verify>
All component files exist.
`pnpm typecheck` passes.
Navigate to /chat:
- Empty state shown initially
- Can type message in input
- Pressing send triggers API call
- Messages appear in list
- AI response streams token-by-token
- Typing indicator shows while waiting
- Auto-scroll follows new content
- Stop button appears during streaming
  </verify>
  <done>
Full chat UI functional: send message, see streaming response, typing indicator, stop button, auto-scroll.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete AI streaming chat flow:
1. Backend: /api/chat Route Handler with AI Gateway, message persistence, token tracking
2. Frontend: Chat UI with useChat hook, streaming rendering, typing indicator, stop button
  </what-built>
  <how-to-verify>
Prerequisites:
- Set AI_GATEWAY_API_KEY in .env.local (get from Vercel Dashboard -> AI -> Gateway)
- Run `pnpm dev` in sidekiq-webapp directory

Test flow:
1. Navigate to http://localhost:3000/sign-in
2. Sign in with test account
3. Navigate to http://localhost:3000/chat
4. Type "Hello, how are you?" and press Send
5. Verify: Your message appears immediately
6. Verify: Typing indicator (three dots) shows briefly
7. Verify: AI response streams in token-by-token
8. Verify: Stop button appears during streaming (click to test cancellation)
9. Verify: Chat auto-scrolls during streaming
10. Scroll up during streaming - verify it stops auto-scrolling
11. Check database: Both user and assistant messages should be saved

Database verification:
```sql
SELECT * FROM message ORDER BY created_at DESC LIMIT 5;
```
Should show user message and assistant message with model, input_tokens, output_tokens, metadata.
  </how-to-verify>
  <resume-signal>Type "approved" if chat flow works correctly, or describe issues found</resume-signal>
</task>

</tasks>

<verification>
1. All component files created
2. `pnpm typecheck` passes
3. `pnpm check` passes
4. Chat page accessible at /chat
5. Messages render correctly
6. Streaming works token-by-token
7. Typing indicator shows during AI thinking
8. Stop button cancels streaming
9. Auto-scroll works intelligently
10. Database contains both user and AI messages
</verification>

<success_criteria>
- User can send a message from /chat page
- User message appears immediately (optimistic UI via useChat)
- AI response streams token-by-token
- Typing indicator shows while AI is processing
- Stop button appears and works during streaming
- Chat auto-scrolls during streaming
- Auto-scroll pauses when user scrolls up
- Messages persist to database (verified via query)
</success_criteria>

<output>
After completion, create `.planning/phases/01-ai-streaming-infrastructure/01-02-SUMMARY.md`
</output>
